---
title: Study Plan for NVIDIA GenAI Certification
date: 2025-09-05
author: AI Agent
status: published
tags:
  - AI
  - certification
  - wanderlog
---

In 2024, I decided to study AI in a more *practical* way, because thanks to my college which offered
a code-heavy AI course back in 2019, I had been aware that AI models are 
by nature highly empirical in solving problems.

Since then, it became quite hard for me to navigate through some serious AI stuff. 
There were just so much of them and most weren't even remotely related to my career, like academic papers.
However, GenAI pulls us all together, and I sensed it is time to set up a practical goal 
to grasp more hands-on experience with GenAI tech stack. 
Why am I eyeing on Nvidia? *They* initiated this boom.

## Goal: To become [NVIDIA-Certified Associate: Generative AI and LLMs(NCA-GENL)](https://www.nvidia.com/en-us/learn/certification/generative-ai-llm-associate/)

It has the following benefits:
1. A certificate to demonstrate GenAI learning results, to some degree at least.
2. An industry-approved learning path has been provided by the exam guide.
3. NVIDIA offers generous GPU usage and pre-set lab environments (mostly why
the courses charge).

### Plan

**Time I spent: 53 hrs** = 50 hrs (online courses and reading) + 3 hrs (exam prep)

**Courses I took:** 

1. *[Generative AI Explained](https://courses.nvidia.com/courses/course-v1:DLI+S-FX-07+V1/)
2. *Getting Started with Deep Learning
3. *Introduction to Transformer-Based Natural Language Processing
4. *Building LLM Applications With Prompt Engineering
5. *Rapid Application Development with Large Language Models (LLMs)
6. Augment your LLM Using Retrieval Augmented Generation
7. Building RAG Agents with LLMs

*P.S. I definitely over-studied. Only 1-5 are recommended by the exam study guide.*

#### Key Concepts
1. AI/ML basics: CNN, LSTM, ReLU, gradient, k-fold, k-means etc.
2. NVIDIA tools: GPU parallel computing, NeMo, Triton, RAPIDS, Nvivida GPU Cloud, 
Trustworthy AI principles etc.
3. LLM knowledge: attention, BERT, LLM model performance metrics (perplexity),
diffusion model, RAG, LoRA, NLP scores.

### Feedback - Worth It?
1. Well, I passed the exam which is very textbook knowledge itself.
2. Meanwhile, I started building a LLM-based product named [ConVerge](/engineering). 
And I find the knowledge being useful, especially during architecture design.